# ğŸ§  LLM Council (Local Multi-Agent AI)

LLM Council is a **local, privacy-friendly AI discussion system** where multiple AI â€œagentsâ€ (Generator, Analyst, Critic, Summarizer) collaborate to think through a topic step by step.

It runs **entirely on your laptop** using **Ollama + Gemma models**, with a simple **Streamlit web interface**.

No cloud APIs. No data leaves your machine.

---

## âœ¨ What it does

Given a topic, the system:

1. Frames the problem clearly
2. Analyzes it logically
3. Critiques assumptions and gaps
4. Produces a balanced final conclusion

All intermediate responses are stored locally in a SQLite database.

---

## ğŸ§© Tech stack

* **Ollama** â€“ runs the AI model locally
* **Gemma (4B recommended)** â€“ the language model
* **Python** â€“ orchestration logic
* **Streamlit** â€“ web UI
* **SQLite** â€“ local storage

---

## ğŸš€ Quick start

### 1ï¸âƒ£ Install Ollama

Download and install from:
ğŸ‘‰ [https://ollama.com](https://ollama.com)

After installation, open a terminal and run:

```bash
ollama pull gemma3:4b
```

(You can also use `gemma3:270m` for lower-end machines.)

---

### 2ï¸âƒ£ Clone this repository

```bash
git clone https://github.com/<your-username>/llm-council.git
cd llm-council
```

---

### 3ï¸âƒ£ Set up Python environment

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Run the app

```bash
streamlit run app.py
```

Your browser will open automatically.
Enter a topic and click **Run Council**.

---

## ğŸ–¥ï¸ Example topics

* *Should AI be used in school grading?*
* *Impact of AI on modern education*
* *Is a four-day work week viable in India?*

---

## ğŸ§  Agents in the council

| Agent      | Role                       |
| ---------- | -------------------------- |
| Generator  | Frames the problem clearly |
| Analyst    | Breaks it down logically   |
| Critic     | Challenges assumptions     |
| Summarizer | Produces final insight     |

---

## ğŸ“‚ Project structure

```
app.py              # Streamlit UI
council_runner.py   # Agent orchestration
agents/             # Individual agent logic
ollama_client.py    # Ollama API wrapper
db/                 # SQLite database
```

---

## ğŸ”’ Privacy & data

* Runs **fully offline**
* No external APIs
* All discussions stored locally in SQLite
* Safe for sensitive topics

---

## ğŸ› ï¸ Requirements

* Python 3.10+
* Ollama installed and running
* ~6â€“8 GB RAM recommended for Gemma 4B

---

## ğŸ“Œ Notes

* First run may be slower (model loading)
* Small models may produce shorter answers
* Designed for learning, research, and experimentation

---

## ğŸ“œ License

MIT License â€” free to use, modify, and share.
